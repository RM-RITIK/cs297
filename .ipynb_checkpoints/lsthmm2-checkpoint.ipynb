{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:35.659908Z",
     "iopub.status.busy": "2023-03-29T08:43:35.659645Z",
     "iopub.status.idle": "2023-03-29T08:43:35.665846Z",
     "shell.execute_reply": "2023-03-29T08:43:35.664422Z",
     "shell.execute_reply.started": "2023-03-29T08:43:35.659882Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loading the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:35.672799Z",
     "iopub.status.busy": "2023-03-29T08:43:35.671937Z",
     "iopub.status.idle": "2023-03-29T08:43:35.689867Z",
     "shell.execute_reply": "2023-03-29T08:43:35.688787Z",
     "shell.execute_reply.started": "2023-03-29T08:43:35.672770Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/kaggle/input/malware-data-rmritik/word2vec_embeddings.pkl', 'rb') as fp:\n",
    "    embed = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:35.692581Z",
     "iopub.status.busy": "2023-03-29T08:43:35.691990Z",
     "iopub.status.idle": "2023-03-29T08:43:35.697489Z",
     "shell.execute_reply": "2023-03-29T08:43:35.696108Z",
     "shell.execute_reply.started": "2023-03-29T08:43:35.692544Z"
    }
   },
   "outputs": [],
   "source": [
    "embed['<PAD>'] = np.zeros((100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Loading the Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:35.700108Z",
     "iopub.status.busy": "2023-03-29T08:43:35.699333Z",
     "iopub.status.idle": "2023-03-29T08:43:38.106818Z",
     "shell.execute_reply": "2023-03-29T08:43:38.104560Z",
     "shell.execute_reply.started": "2023-03-29T08:43:35.700073Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/malware-data-rmritik/malware_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:38.108808Z",
     "iopub.status.busy": "2023-03-29T08:43:38.108412Z",
     "iopub.status.idle": "2023-03-29T08:43:38.142687Z",
     "shell.execute_reply": "2023-03-29T08:43:38.141017Z",
     "shell.execute_reply.started": "2023-03-29T08:43:38.108766Z"
    }
   },
   "outputs": [],
   "source": [
    "counts_family = data.groupby('Malware Family')['Malware Family'].transform(len)\n",
    "mask = (counts_family > 50)\n",
    "data = data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:38.148638Z",
     "iopub.status.busy": "2023-03-29T08:43:38.147953Z",
     "iopub.status.idle": "2023-03-29T08:43:40.457994Z",
     "shell.execute_reply": "2023-03-29T08:43:40.456325Z",
     "shell.execute_reply.started": "2023-03-29T08:43:38.148586Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if len(row['OpCode Sequence'].split(' ')) < 100:\n",
    "        data = data.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:40.459855Z",
     "iopub.status.busy": "2023-03-29T08:43:40.459476Z",
     "iopub.status.idle": "2023-03-29T08:43:42.375345Z",
     "shell.execute_reply": "2023-03-29T08:43:42.374203Z",
     "shell.execute_reply.started": "2023-03-29T08:43:40.459815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27503\n"
     ]
    }
   ],
   "source": [
    "max_len = float('-inf')\n",
    "for index, row in data.iterrows():\n",
    "    max_len = max(max_len, len(row['OpCode Sequence'].split(' ')))\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.377367Z",
     "iopub.status.busy": "2023-03-29T08:43:42.376898Z",
     "iopub.status.idle": "2023-03-29T08:43:42.470575Z",
     "shell.execute_reply": "2023-03-29T08:43:42.469531Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.377327Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/malware-data-rmritik/cell_state_dict.pkl', 'rb') as fp:\n",
    "    cell_states = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.474074Z",
     "iopub.status.busy": "2023-03-29T08:43:42.473762Z",
     "iopub.status.idle": "2023-03-29T08:43:42.482107Z",
     "shell.execute_reply": "2023-03-29T08:43:42.481158Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.474046Z"
    }
   },
   "outputs": [],
   "source": [
    "cell_states_list = []\n",
    "for key in cell_states:\n",
    "    cell_states_list.append(cell_states[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.484385Z",
     "iopub.status.busy": "2023-03-29T08:43:42.483929Z",
     "iopub.status.idle": "2023-03-29T08:43:42.494967Z",
     "shell.execute_reply": "2023-03-29T08:43:42.493938Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.484280Z"
    }
   },
   "outputs": [],
   "source": [
    "data['cell states'] = cell_states_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.496993Z",
     "iopub.status.busy": "2023-03-29T08:43:42.496506Z",
     "iopub.status.idle": "2023-03-29T08:43:42.507792Z",
     "shell.execute_reply": "2023-03-29T08:43:42.506673Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.496959Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns = ['Malware Family'])\n",
    "y = data['Malware Family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.509546Z",
     "iopub.status.busy": "2023-03-29T08:43:42.509119Z",
     "iopub.status.idle": "2023-03-29T08:43:42.933326Z",
     "shell.execute_reply": "2023-03-29T08:43:42.932190Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.509508Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.935775Z",
     "iopub.status.busy": "2023-03-29T08:43:42.935304Z",
     "iopub.status.idle": "2023-03-29T08:43:42.949371Z",
     "shell.execute_reply": "2023-03-29T08:43:42.948294Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.935729Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def prepare_data(X_df, y_df):\n",
    "    X_tokens = []\n",
    "    y_labels = []\n",
    "    cell_states = []\n",
    "    for index, row in X_df.iterrows():\n",
    "        cell_states.append(row['cell states'])\n",
    "        if len(row['OpCode Sequence'].split(' ')) >= 1000:\n",
    "            X_tokens.append(row['OpCode Sequence'].split(' ')[0:1000])\n",
    "        else:\n",
    "            X_tokens.append(row['OpCode Sequence'].split(' ') + ['<PAD>']*(1000 - len(row['OpCode Sequence'].split(' '))))\n",
    "    \n",
    "    for index, values in y_df.iteritems():\n",
    "        y_labels.append(values)\n",
    "        \n",
    "    X = []\n",
    "    for row in X_tokens:\n",
    "        row_embed = []\n",
    "        for word in row:\n",
    "            row_embed.append(embed[word])\n",
    "        row_embed = np.array(row_embed)\n",
    "        X.append(row_embed)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "    y = onehot_encoder.fit_transform(integer_encoded)\n",
    "    y = y.reshape((len(y), 1, 7))\n",
    "    \n",
    "    return X, y, cell_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:42.951902Z",
     "iopub.status.busy": "2023-03-29T08:43:42.951580Z",
     "iopub.status.idle": "2023-03-29T08:43:55.463859Z",
     "shell.execute_reply": "2023-03-29T08:43:55.462588Z",
     "shell.execute_reply.started": "2023-03-29T08:43:42.951873Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, cell_states_train = prepare_data(X_train, y_train)\n",
    "X_test, y_test, cell_states_test = prepare_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.468767Z",
     "iopub.status.busy": "2023-03-29T08:43:55.468401Z",
     "iopub.status.idle": "2023-03-29T08:43:55.475929Z",
     "shell.execute_reply": "2023-03-29T08:43:55.474656Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.468736Z"
    }
   },
   "outputs": [],
   "source": [
    "nr_categories = len(data[\"Malware Family\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Some Basic Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.478278Z",
     "iopub.status.busy": "2023-03-29T08:43:55.477614Z",
     "iopub.status.idle": "2023-03-29T08:43:55.505319Z",
     "shell.execute_reply": "2023-03-29T08:43:55.504241Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.478240Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_orthogonal(param):\n",
    "    \"\"\"\n",
    "    Initializes weight parameters orthogonally.\n",
    "    This is a common initiailization for recurrent neural networks.\n",
    "    \n",
    "    Refer to this paper for an explanation of this initialization:\n",
    "    https://arxiv.org/abs/1312.6120\n",
    "    \"\"\"\n",
    "    if param.ndim < 2:\n",
    "        raise ValueError(\"Only parameters with 2 or more dimensions are supported.\")\n",
    "\n",
    "    rows, cols = param.shape\n",
    "    \n",
    "    new_param = np.random.randn(rows, cols)\n",
    "    \n",
    "    if rows < cols:\n",
    "        new_param = new_param.T\n",
    "    \n",
    "    # Compute QR factorization\n",
    "    q, r = np.linalg.qr(new_param)\n",
    "    \n",
    "    # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
    "    d = np.diag(r, 0)\n",
    "    ph = np.sign(d)\n",
    "    q *= ph\n",
    "\n",
    "    if rows < cols:\n",
    "        q = q.T\n",
    "    \n",
    "    new_param = q\n",
    "    \n",
    "    return new_param\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise sigmoid activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = 1 / (1 + np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return f * (1 - f)\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f\n",
    "\n",
    "def tanh(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the element-wise tanh activation function for an array x.\n",
    "\n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = (np.exp(x_safe)-np.exp(-x_safe))/(np.exp(x_safe)+np.exp(-x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        return 1-f**2\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f\n",
    "\n",
    "def softmax(x, derivative=False):\n",
    "    \"\"\"\n",
    "    Computes the softmax for an array x.\n",
    "    \n",
    "    Args:\n",
    "     `x`: the array where the function is applied\n",
    "     `derivative`: if set to True will return the derivative instead of the forward pass\n",
    "    \"\"\"\n",
    "    x_safe = x + 1e-12\n",
    "    f = np.exp(x_safe) / np.sum(np.exp(x_safe))\n",
    "    \n",
    "    if derivative: # Return the derivative of the function evaluated at x\n",
    "        pass # We will not need this one\n",
    "    else: # Return the forward pass of the function at x\n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> LSTHMM Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.507197Z",
     "iopub.status.busy": "2023-03-29T08:43:55.506817Z",
     "iopub.status.idle": "2023-03-29T08:43:55.543665Z",
     "shell.execute_reply": "2023-03-29T08:43:55.542489Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.507159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_f: (100, 200)\n",
      "W_i: (100, 200)\n",
      "W_g: (100, 200)\n",
      "W_o: (100, 200)\n",
      "W_v: (7, 100)\n",
      "b_i: (100, 1)\n",
      "b_g: (100, 1)\n",
      "b_o: (100, 1)\n",
      "b_v: (100, 1)\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "embed_size = 100\n",
    "z_size = hidden_size + embed_size \n",
    "\n",
    "\n",
    "def init_lstm(hidden_size, embed_size, z_size):\n",
    "    \"\"\"\n",
    "    Initializes our LSTM network.\n",
    "    \n",
    "    Args:\n",
    "     `hidden_size`: the dimensions of the hidden state\n",
    "     `vocab_size`: the dimensions of our vocabulary\n",
    "     `z_size`: the dimensions of the concatenated input \n",
    "    \"\"\"\n",
    "    # Weight matrix (forget gate)\n",
    "    W_f = np.zeros((hidden_size, z_size))\n",
    "    \n",
    "    # Bias for forget gate\n",
    "    b_f = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Weight matrix (input gate)\n",
    "    W_i = np.zeros((hidden_size, z_size))\n",
    "    \n",
    "    # Bias for input gate\n",
    "    b_i = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Weight matrix (candidate)\n",
    "    W_g = np.zeros((hidden_size, z_size))\n",
    "    \n",
    "    # Bias for candidate\n",
    "    b_g = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Weight matrix of the output gate\n",
    "    W_o = np.zeros((hidden_size, z_size))\n",
    "    \n",
    "    # Bias for output gate\n",
    "    b_o = np.zeros((hidden_size, 1))\n",
    "\n",
    "    # Weight matrix relating the hidden-state to the output\n",
    "    W_v = np.zeros((nr_categories, hidden_size))\n",
    "    \n",
    "    # Bias for logits\n",
    "    b_v = np.zeros((nr_categories, 1))\n",
    "    \n",
    "    # Initialize weights according to https://arxiv.org/abs/1312.6120\n",
    "    W_f = init_orthogonal(W_f)\n",
    "    W_i = init_orthogonal(W_i)\n",
    "    W_g = init_orthogonal(W_g)\n",
    "    W_o = init_orthogonal(W_o)\n",
    "    W_v = init_orthogonal(W_v)\n",
    "\n",
    "    return W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v\n",
    "\n",
    "\n",
    "params = init_lstm(hidden_size=hidden_size, embed_size=embed_size, z_size=z_size)\n",
    "print('W_f:', params[0].shape)\n",
    "print('W_i:', params[1].shape)\n",
    "print('W_g:', params[2].shape)\n",
    "print('W_o:', params[3].shape)\n",
    "print('W_v:', params[4].shape)\n",
    "print('b_i:', params[5].shape)\n",
    "print('b_g:', params[6].shape)\n",
    "print('b_o:', params[7].shape)\n",
    "print('b_v:', params[8].shape)\n",
    "\n",
    "for param in params:\n",
    "    assert param.ndim == 2, \\\n",
    "        'all parameters should be 2-dimensional '\\\n",
    "        '(hint: a dimension can simply have size 1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.545788Z",
     "iopub.status.busy": "2023-03-29T08:43:55.545230Z",
     "iopub.status.idle": "2023-03-29T08:43:55.955552Z",
     "shell.execute_reply": "2023-03-29T08:43:55.954185Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.545754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected output: \n",
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "predicted output: \n",
      "[[0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      "  0.14285714]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import signal\n",
    "def forward(inputs, h_prev, C_prev, p):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- your input data at timestep \"t\", numpy array of shape (n_x, m).\n",
    "    h_prev -- Hidden state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    C_prev -- Memory state at timestep \"t-1\", numpy array of shape (n_a, m)\n",
    "    p -- python list containing:\n",
    "                        W_f -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_f -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
    "                        W_i -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_i -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
    "                        W_g -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_g --  Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
    "                        W_o -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_o --  Bias of the output gate, numpy array of shape (n_a, 1)\n",
    "                        W_v -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_v, n_a)\n",
    "                        b_v -- Bias relating the hidden-state to the output, numpy array of shape (n_v, 1)\n",
    "    Returns:\n",
    "    z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s -- lists of size m containing the computations in each forward pass\n",
    "    outputs -- prediction at timestep \"t\", numpy array of shape (n_v, m)\n",
    "    \"\"\"\n",
    "    assert h_prev.shape == (hidden_size, 1)\n",
    "    assert C_prev.shape == (hidden_size, 1)\n",
    "\n",
    "    # First we unpack our parameters\n",
    "    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p\n",
    "    \n",
    "    # Save a list of computations for each of the components in the LSTM\n",
    "    x_s, z_s, f_s, i_s,  = [], [] ,[], []\n",
    "    g_s, C_s, o_s, h_s = [], [] ,[], []\n",
    "    v_s, output_s =  [], [] \n",
    "    \n",
    "    # Append the initial cell and hidden state to their respective lists\n",
    "    h_s.append(h_prev)\n",
    "    C_s.append(C_prev)\n",
    "    \n",
    "    for x in inputs:\n",
    "        x = x.reshape(100, 1)\n",
    "        # Concatenate input and hidden state\n",
    "        z = np.row_stack((h_prev, x))\n",
    "        z_s.append(z)\n",
    "        \n",
    "        # Calculate forget gate\n",
    "        f = softmax(np.dot(W_f, z) + b_f)\n",
    "        f_s.append(f)\n",
    "        \n",
    "        # Calculate input gate\n",
    "        i = softmax(np.dot(W_i, z) + b_i)\n",
    "        i_s.append(i)\n",
    "        \n",
    "        # Calculate candidate\n",
    "        g = tanh(np.dot(W_g, z) + b_g)\n",
    "        g_s.append(g)\n",
    "        \n",
    "        # Calculate memory state\n",
    "        C_prev = np.multiply(C_prev, f) + np.multiply(g, i)\n",
    "        C_s.append(C_prev)\n",
    "        \n",
    "        # Calculate output gate\n",
    "        o = softmax(np.dot(W_o, z) + b_o)\n",
    "        o_s.append(o)\n",
    "        \n",
    "        # Calculate hidden state\n",
    "        h_prev = o * tanh(C_prev)\n",
    "        h_s.append(h_prev)\n",
    "\n",
    "        # Calculate logits\n",
    "        v = np.dot(W_v, h_prev) + b_v\n",
    "        v_s.append(v)\n",
    "        \n",
    "        # Calculate softmax\n",
    "        output = softmax(v)\n",
    "        output_s.append(output.reshape(1, 7))\n",
    "    \n",
    "    output_s = np.array(output_s)\n",
    "\n",
    "    return z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s[-1]\n",
    "\n",
    "\n",
    "# Get first sentence in test set\n",
    "inputs, targets = X_train[0], y_train[0]\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "h = np.zeros((hidden_size, 1))\n",
    "c = cell_states_train[0].reshape((hidden_size, 1))\n",
    "\n",
    "# Forward pass\n",
    "z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs, h, c, params)\n",
    "\n",
    "print('expected output: ')\n",
    "print(y_train[0])\n",
    "\n",
    "print('predicted output: ')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.962368Z",
     "iopub.status.busy": "2023-03-29T08:43:55.961528Z",
     "iopub.status.idle": "2023-03-29T08:43:55.977240Z",
     "shell.execute_reply": "2023-03-29T08:43:55.975791Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.962315Z"
    }
   },
   "outputs": [],
   "source": [
    "def clip_gradient_norm(grads, max_norm=0.25):\n",
    "    \"\"\"\n",
    "    Clips gradients to have a maximum norm of `max_norm`.\n",
    "    This is to prevent the exploding gradients problem.\n",
    "    \"\"\" \n",
    "    # Set the maximum of the norm to be of type float\n",
    "    max_norm = float(max_norm)\n",
    "    total_norm = 0\n",
    "    \n",
    "    # Calculate the L2 norm squared for each gradient and add them to the total norm\n",
    "    for grad in grads:\n",
    "        grad_norm = np.sum(np.power(grad, 2))\n",
    "        total_norm += grad_norm\n",
    "    \n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    \n",
    "    # Calculate clipping coeficient\n",
    "    clip_coef = max_norm / (total_norm + 1e-6)\n",
    "    \n",
    "    # If the total norm is larger than the maximum allowable norm, then clip the gradient\n",
    "    if clip_coef < 1:\n",
    "        for grad in grads:\n",
    "            grad *= clip_coef\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:55.987810Z",
     "iopub.status.busy": "2023-03-29T08:43:55.984168Z",
     "iopub.status.idle": "2023-03-29T08:43:56.037517Z",
     "shell.execute_reply": "2023-03-29T08:43:56.035894Z",
     "shell.execute_reply.started": "2023-03-29T08:43:55.987750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get a loss of:\n",
      "0.27798716415075786\n"
     ]
    }
   ],
   "source": [
    "def backward(z, f, i, g, C, o, h, v, outputs, targets, p = params):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    z -- your concatenated input data  as a list of size m.\n",
    "    f -- your forget gate computations as a list of size m.\n",
    "    i -- your input gate computations as a list of size m.\n",
    "    g -- your candidate computations as a list of size m.\n",
    "    C -- your Cell states as a list of size m+1.\n",
    "    o -- your output gate computations as a list of size m.\n",
    "    h -- your Hidden state computations as a list of size m+1.\n",
    "    v -- your logit computations as a list of size m.\n",
    "    outputs -- your outputs as a list of size m.\n",
    "    targets -- your targets as a list of size m.\n",
    "    p -- python list containing:\n",
    "                        W_f -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_f -- Bias of the forget gate, numpy array of shape (n_a, 1)\n",
    "                        W_i -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_i -- Bias of the update gate, numpy array of shape (n_a, 1)\n",
    "                        W_g -- Weight matrix of the first \"tanh\", numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_g --  Bias of the first \"tanh\", numpy array of shape (n_a, 1)\n",
    "                        W_o -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)\n",
    "                        b_o --  Bias of the output gate, numpy array of shape (n_a, 1)\n",
    "                        W_v -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_v, n_a)\n",
    "                        b_v -- Bias relating the hidden-state to the output, numpy array of shape (n_v, 1)\n",
    "    Returns:\n",
    "    loss -- crossentropy loss for all elements in output\n",
    "    grads -- lists of gradients of every element in p\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack parameters\n",
    "    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p\n",
    "\n",
    "    # Initialize gradients as zero\n",
    "    W_f_d = np.zeros_like(W_f)\n",
    "    b_f_d = np.zeros_like(b_f)\n",
    "\n",
    "    W_i_d = np.zeros_like(W_i)\n",
    "    b_i_d = np.zeros_like(b_i)\n",
    "\n",
    "    W_g_d = np.zeros_like(W_g)\n",
    "    b_g_d = np.zeros_like(b_g)\n",
    "\n",
    "    W_o_d = np.zeros_like(W_o)\n",
    "    b_o_d = np.zeros_like(b_o)\n",
    "\n",
    "    W_v_d = np.zeros_like(W_v)\n",
    "    b_v_d = np.zeros_like(b_v)\n",
    "    \n",
    "    # Set the next cell and hidden state equal to zero\n",
    "    dh_next = np.zeros_like(h[0])\n",
    "    dC_next = np.zeros_like(C[0])\n",
    "        \n",
    "    # Track loss\n",
    "    loss = 0\n",
    "    \n",
    "    for t in reversed(range(len(outputs))):\n",
    "        \n",
    "        # Compute the cross entropy\n",
    "        loss += -np.mean(np.log(outputs[t]) * targets[t])\n",
    "        # Get the previous hidden cell state\n",
    "        C_prev= C[t-1]\n",
    "        \n",
    "        # Compute the derivative of the relation of the hidden-state to the output gate\n",
    "        dv = np.copy(outputs[t])\n",
    "        dv[np.argmax(targets[t])] -= 1\n",
    "        dv = dv.reshape(7, 1)\n",
    "\n",
    "        # Update the gradient of the relation of the hidden-state to the output gate\n",
    "        W_v_d += np.dot(dv, h[t].T)\n",
    "        b_v_d += dv\n",
    "\n",
    "        # Compute the derivative of the hidden state and output gate\n",
    "        dh = np.dot(W_v.T, dv)        \n",
    "        dh += dh_next\n",
    "        do = dh * tanh(C[t])\n",
    "        do = sigmoid(o[t], derivative=True)*do\n",
    "        \n",
    "        # Update the gradients with respect to the output gate\n",
    "        W_o_d += np.dot(do, z[t].T)\n",
    "        b_o_d += do\n",
    "\n",
    "        # Compute the derivative of the cell state and candidate g\n",
    "        dC = np.copy(dC_next)\n",
    "        dC += dh * o[t] * tanh(tanh(C[t]), derivative=True)\n",
    "        dg = dC * i[t]\n",
    "        dg = tanh(g[t], derivative=True) * dg\n",
    "        \n",
    "        # Update the gradients with respect to the candidate\n",
    "        W_g_d += np.dot(dg, z[t].T)\n",
    "        b_g_d += dg\n",
    "\n",
    "        # Compute the derivative of the input gate and update its gradients\n",
    "        di = dC * g[t]\n",
    "        di = sigmoid(i[t], True) * di\n",
    "        W_i_d += np.dot(di, z[t].T)\n",
    "        b_i_d += di\n",
    "\n",
    "        # Compute the derivative of the forget gate and update its gradients\n",
    "        df = dC * C_prev\n",
    "        df = sigmoid(f[t]) * df\n",
    "        W_f_d += np.dot(df, z[t].T)\n",
    "        b_f_d += df\n",
    "\n",
    "        # Compute the derivative of the input and update the gradients of the previous hidden and cell state\n",
    "        dz = (np.dot(W_f.T, df)\n",
    "             + np.dot(W_i.T, di)\n",
    "             + np.dot(W_g.T, dg)\n",
    "             + np.dot(W_o.T, do))\n",
    "        dh_prev = dz[:hidden_size, :]\n",
    "        dC_prev = f[t] * dC\n",
    "        \n",
    "    grads= W_f_d, W_i_d, W_g_d, W_o_d, W_v_d, b_f_d, b_i_d, b_g_d, b_o_d, b_v_d\n",
    "    \n",
    "    # Clip gradients\n",
    "    grads = clip_gradient_norm(grads)\n",
    "    \n",
    "    return loss, grads\n",
    "\n",
    "\n",
    "# Perform a backward pass\n",
    "loss, grads = backward(z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs, targets, params)\n",
    "\n",
    "print('We get a loss of:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:56.046212Z",
     "iopub.status.busy": "2023-03-29T08:43:56.043006Z",
     "iopub.status.idle": "2023-03-29T08:43:56.055388Z",
     "shell.execute_reply": "2023-03-29T08:43:56.053799Z",
     "shell.execute_reply.started": "2023-03-29T08:43:56.046159Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, lr=1e-3):\n",
    "    # Take a step\n",
    "    for param, grad in zip(params, grads):\n",
    "        param -= lr * grad\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T08:43:56.062445Z",
     "iopub.status.busy": "2023-03-29T08:43:56.061319Z",
     "iopub.status.idle": "2023-03-29T19:24:01.736752Z",
     "shell.execute_reply": "2023-03-29T19:24:01.735049Z",
     "shell.execute_reply.started": "2023-03-29T08:43:56.062395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854bf8dbabfe4d75875d748e9f2ebdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "face4d3543704304ac72b4d5a45adf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958abc5641e844b79d4c9cd41ba42f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 0.2521846136807574, validation loss: 0.27798856592866306\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481040fb2b1742ffa5105057f5bdbaf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865ca13abe0e4344992e200bd6b0197b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, training loss: 0.26358083304801533, validation loss: 0.27070870399565883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e78012ac46463997db83fe59a98268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8a8392b1594e03b45cf3cd87e78ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, training loss: 0.26332418336272334, validation loss: 0.2695460742581538\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f26af1dc4c4ebb8bda51b444a1ceb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d87df9dd6a4e04942b6865038b6934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, training loss: 0.26331182058914676, validation loss: 0.2693232299005647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed8286d6e654a63a4fdcbae58d4d625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725981d2379746ffae182e2a7d02e9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, training loss: 0.2632718996813872, validation loss: 0.26923036451004695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667d5c88d06246e2ac58bd10c887ee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6155b99616e84e2d9e8acd44bef529dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, training loss: 0.26323021746115083, validation loss: 0.2691445438040103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1e489badfe45a3893912cd23b0d0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf8e5f53d184c8ab60d4fa93341c5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, training loss: 0.2633465594003768, validation loss: 0.2689783067879229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4178a80f9de249b195569bd90747cf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d24ef913274bbcbbbaa3eef8e273e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, training loss: 0.2639300759072704, validation loss: 0.26889696372815275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9740b4dffe4552af14913eb0ebc571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30fc2562c26e4c30b8e1f769e0e48acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, training loss: 0.2627593418623344, validation loss: 0.2693870281022726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1488973f86c41a0ab61a5dfb8a53dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104fecdc689d477eaa8e2edd380b3a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, training loss: 0.2612551367711, validation loss: 0.26679402469043423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f04b681a4fa4095b51cfe1b934193bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a159a23ef549e8ab58c1e5d2a6bcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, training loss: 0.26089451967917754, validation loss: 0.2654057832236551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1ec09ffa7544389658eb36a96f7b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cfa00d97734a99afbf2758133dba70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, training loss: 0.2608862609317133, validation loss: 0.2653377991318486\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6a5fc975cc422b945c3d8a2c635d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e23a7a073743019cf3d04e1c09abd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, training loss: 0.260880807893643, validation loss: 0.26551493875295845\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62de78bf5c5744df9554ca379f038d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12be4c08fa5e4ca286edeea7bf5d1899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23/2292565289.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mz_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23/4027193952.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(inputs, h_prev, C_prev, p)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Concatenate input and hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mz_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import math\n",
    "# Hyper-parameters\n",
    "num_epochs = 100\n",
    "\n",
    "# Initialize a new network\n",
    "hidden_size = 100\n",
    "embed_size = 100\n",
    "z_size = hidden_size + embed_size \n",
    "params = init_lstm(hidden_size=hidden_size, embed_size=embed_size, z_size=z_size)\n",
    "\n",
    "# Initialize hidden state as zeros\n",
    "hidden_state = np.zeros((hidden_size, 1))\n",
    "\n",
    "# Track loss\n",
    "training_loss, validation_loss = [], []\n",
    "\n",
    "# For each epoch\n",
    "for i in trange(num_epochs):\n",
    "    \n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "    # For each sentence in validation set\n",
    "    for j in tqdm(range(len(X_test))):\n",
    "        \n",
    "        inputs = X_test[j]\n",
    "        targets = y_test[j]\n",
    "        \n",
    "        h = np.zeros((hidden_size, 1))\n",
    "        c = cell_states_test[j].reshape(hidden_size, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs, h, c, params)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss, _ = backward(z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs, targets, params)\n",
    "        \n",
    "        # Update loss\n",
    "        if math.isnan(loss) == False:\n",
    "            epoch_validation_loss += loss\n",
    "    \n",
    "    # For each sentence in training set\n",
    "    for j in tqdm(range(len(X_train))):\n",
    "        \n",
    "        inputs = X_train[j]\n",
    "        targets = y_train[j]\n",
    "\n",
    "        # Initialize hidden state and cell state as zeros\n",
    "        h = np.zeros((hidden_size, 1))\n",
    "        c = cell_states_train[j].reshape(hidden_size, 1)\n",
    "\n",
    "        # Forward pass\n",
    "        z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs, h, c, params)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss, grads = backward(z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs, targets, params)\n",
    "        \n",
    "        # Update parameters\n",
    "        params = update_parameters(params, grads, lr=1e-1)\n",
    "        \n",
    "        # Update loss\n",
    "        if math.isnan(loss) == False:\n",
    "            epoch_training_loss += loss\n",
    "                \n",
    "    # Save loss for plot\n",
    "    training_loss.append(epoch_training_loss/len(X_train))\n",
    "    validation_loss.append(epoch_validation_loss/len(X_test))\n",
    "    print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n",
    "\n",
    "\n",
    "\n",
    "# Plot training and validation loss\n",
    "epoch = np.arange(len(training_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('NLL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:24:39.713379Z",
     "iopub.status.busy": "2023-03-29T19:24:39.712780Z",
     "iopub.status.idle": "2023-03-29T19:24:40.271361Z",
     "shell.execute_reply": "2023-03-29T19:24:40.270123Z",
     "shell.execute_reply.started": "2023-03-29T19:24:39.713335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch = np.arange(len(training_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
    "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch'), plt.ylabel('NLL')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:25:31.236328Z",
     "iopub.status.busy": "2023-03-29T19:25:31.235377Z",
     "iopub.status.idle": "2023-03-29T19:34:58.910915Z",
     "shell.execute_reply": "2023-03-29T19:34:58.909839Z",
     "shell.execute_reply.started": "2023-03-29T19:25:31.236282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b65fff37874dbc891bed9f3606a7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1608 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_outputs = []\n",
    "for j in tqdm(range(len(X_test))):\n",
    "        \n",
    "        inputs = X_test[j]\n",
    "        targets = y_test[j]\n",
    "        \n",
    "        h = np.zeros((hidden_size, 1))\n",
    "        c = np.zeros((hidden_size, 1))\n",
    "\n",
    "        # Forward pass\n",
    "        z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs, h, c, params)\n",
    "        predicted_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:35:26.462896Z",
     "iopub.status.busy": "2023-03-29T19:35:26.462542Z",
     "iopub.status.idle": "2023-03-29T19:35:26.473959Z",
     "shell.execute_reply": "2023-03-29T19:35:26.472889Z",
     "shell.execute_reply.started": "2023-03-29T19:35:26.462865Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_output_class = []\n",
    "for output in predicted_outputs:\n",
    "    class_index = np.argmax(output)\n",
    "    predicted_output_class.append(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:35:35.711741Z",
     "iopub.status.busy": "2023-03-29T19:35:35.711073Z",
     "iopub.status.idle": "2023-03-29T19:35:35.736070Z",
     "shell.execute_reply": "2023-03-29T19:35:35.735023Z",
     "shell.execute_reply.started": "2023-03-29T19:35:35.711706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_output_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:35:50.589334Z",
     "iopub.status.busy": "2023-03-29T19:35:50.588760Z",
     "iopub.status.idle": "2023-03-29T19:35:50.615403Z",
     "shell.execute_reply": "2023-03-29T19:35:50.614181Z",
     "shell.execute_reply.started": "2023-03-29T19:35:50.589289Z"
    }
   },
   "outputs": [],
   "source": [
    "actual_output_class = []\n",
    "for output in y_test:\n",
    "    class_index = np.argmax(output)\n",
    "    actual_output_class.append(class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-29T19:35:57.554443Z",
     "iopub.status.busy": "2023-03-29T19:35:57.554069Z",
     "iopub.status.idle": "2023-03-29T19:35:57.563791Z",
     "shell.execute_reply": "2023-03-29T19:35:57.562485Z",
     "shell.execute_reply.started": "2023-03-29T19:35:57.554410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5223880597014925"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(actual_output_class, predicted_output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
